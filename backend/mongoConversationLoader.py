from pymongo import MongoClient
from langchain.memory import ConversationSummaryMemory
# from langchain.chat_models import ChatGoogleGenerativeAI
from llm import get_gemini_response,remove_markdown
import asyncio
class MongoConversationLoader:
    def __init__(self, mongo_uri, db_name, collection_name, llm):
        self.client = MongoClient(mongo_uri)
        self.collection = self.client[db_name][collection_name]
        self.llm = llm

    # todo:é€šè¿‡langchain.conversationSummaryMemoryæ€»ç»“å†å²ä¿¡æ¯ï¼Œä½†ä¸geminiå…¼å®¹æ€§å·®ï¼Œæ— æ³•è¿è¡Œ
    def load_conversation_memory(self, phone, conversation_id):
        # æ‰“å°å½“å‰æŸ¥è¯¢æ¡ä»¶
        print(f"ğŸ” æ­£åœ¨æŸ¥è¯¢ MongoDB ä¸­ phone = {phone} ä¸” conversation_id = {conversation_id} çš„ä¼šè¯...")

        self.debug_all_documents()  # æ‰“å°å…¨éƒ¨æ–‡æ¡£ï¼Œä¾¿äº debug
        query = {"phone": phone, "conversation_id": conversation_id}
        document = self.collection.find_one(query)
        if not document:
            raise ValueError(f"âŒ æœªæ‰¾åˆ°ç”¨æˆ· {phone} çš„ä¼šè¯ IDï¼š{conversation_id}")

        messages = document.get("messages", [])
        memory = ConversationSummaryMemory(llm=self.llm, memory_key="chat_history", return_messages=True)

        for i in range(0, len(messages), 2):
            user_msg = messages[i]["content"] if messages[i]["role"] == "user" else ""
            ai_msg = messages[i + 1]["content"] if i + 1 < len(messages) and messages[i + 1][
                "role"] == "assistant" else ""
            if user_msg:
                memory.save_context({"input": user_msg}, {"output": ai_msg})

        return memory


    # æ‰“å°mongodbå¯¹è¯æ–‡æ¡£
    def debug_all_documents(self):
        print("ğŸ“„ æ­£åœ¨æ‰“å° MongoDB ä¸­çš„æ‰€æœ‰å¯¹è¯æ–‡æ¡£ï¼ˆä»…é™å‰10æ¡ï¼‰:")
        for doc in self.collection.find().limit(10):
            print(
                f"ğŸ“Œ phone: {doc.get('phone')}, conversation_id: {doc.get('conversation_id')}, messages_len: {len(doc.get('messages', []))}")


    # todo:æ‰‹åŠ¨è°ƒç”¨geiminiè¿›è¡Œæ€»ç»“
    # ä» MongoDB è·å–ä¼šè¯å†å²
    def get_conversation_history(self, phone, conversation_id):
        conversation = self.collection.find_one({"phone": phone, "conversation_id": conversation_id})
        if not conversation:
            raise ValueError(f"âŒ æœªæ‰¾åˆ°ç”¨æˆ· {phone} çš„ä¼šè¯ IDï¼š{conversation_id}")
        return conversation['messages']

    # æ‹¼æ¥å†å²å¯¹è¯ç”Ÿæˆ prompt
    def create_summary_prompt(self, messages):
        prompt = "ä»¥ä¸‹æ˜¯å¯¹è¯å†å²ï¼Œç®€è¦æ€»ç»“ç”¨æˆ·å’ŒåŠ©æ‰‹çš„äº’åŠ¨å†…å®¹ï¼š\n\n"
        # éå†æ¶ˆæ¯åˆ—è¡¨ï¼Œå°†ç”¨æˆ·å’ŒåŠ©æ‰‹çš„æ¶ˆæ¯æ‹¼æ¥æˆå¯¹è¯
        for msg in messages:
            if msg["role"] == "user":
                prompt += f"ç”¨æˆ·: {msg['content']}\n"
            elif msg["role"] == "assistant":
                prompt += f"åŠ©æ‰‹: {msg['content']}\n"
        prompt += "\næ€»ç»“ï¼š"
        print("prompt", prompt)
        return prompt

    # ä½¿ç”¨ Gemini æˆ–å…¶ä»– LLM åšæ€»ç»“
    def generate_summary(self, prompt):
        #response = self.llm.invoke(prompt)
        response= asyncio.run(get_gemini_response(prompt))
        print('response',response)
        return response["content"]

    # è·å–å¹¶æ€»ç»“ä¼šè¯
    def get_conversation_summary(self, phone, conversation_id):
        print(f"ğŸ” æ­£åœ¨æŸ¥è¯¢ MongoDB ä¸­ phone = {phone} ä¸” conversation_id = {conversation_id} çš„ä¼šè¯...")
        messages = self.get_conversation_history(phone, conversation_id)
        self.debug_all_documents()  # æ‰“å°å…¨éƒ¨æ–‡æ¡£ï¼Œä¾¿äº debug
        # æ‹¼æ¥ prompt å¹¶ç”Ÿæˆæ€»ç»“
        prompt = self.create_summary_prompt(messages)
        summary =self.generate_summary(prompt)

        return remove_markdown(summary)